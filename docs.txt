1. Introduction (30â€“45 sec)

ğŸ‘¤ You on camera (optional) or just voice over:

â€œHello everyone, my name is Shivam Rawat, and today Iâ€™ll be presenting my project â€” a chatbot built using LangGraph, Groq LLM, Tavily Search, and Streamlit. The idea is to create a chatbot that can intelligently answer questions, and if it doesnâ€™t know something, it can call a web search tool to fetch real-time information.â€

2. Tech Stack (30 sec)

ğŸ’» Show a slide or quickly explain with your code open:

â€œThe tech stack includes:

LangGraph, which manages the flow between the agent and tools.

Groqâ€™s LLM â€“ openai/gpt-oss-20b, which generates the chatbotâ€™s responses.

Tavily Search API, which fetches live search results from the web.

And finally, Streamlit, which I used to build a simple user interface.â€

3. Workflow Explanation (1 min)

ğŸ“Š Show a diagram or explain while pointing at code:

â€œThe workflow works like this:

The user types a message into the chatbot interface.

The message goes to the Agent (Groq LLM).

If the model detects that it needs real-time info, it makes a tool call to Tavily Search.

Tavily fetches results and sends them back.

The Agent uses those results to generate a final answer.

Finally, the answer is displayed in Streamlit.â€

4. Live Demo (2â€“3 min)

ğŸ’» Switch to your Streamlit app and show live examples:

â€œLetâ€™s see the chatbot in action.

First, Iâ€™ll ask a simple question: â€˜What is the capital of France?â€™ â€” here, the LLM directly knows the answer.

Next, Iâ€™ll ask something that needs real-time information: â€˜What is the latest news about SpaceX?â€™ â€” now the model decides to call Tavily Search, fetches recent updates, and then gives me a summarized answer.

Finally, let me try a casual question: â€˜Tell me a fun fact about cats.â€™ â€” this shows how it can also respond conversationally.â€

5. Code Walkthrough (2â€“3 min)

ğŸ‘¨â€ğŸ’» Switch to your IDE (VS Code or wherever you wrote code):

â€œNow, let me quickly walk you through the code.

Inside the chatbot class, I define the LLM and bind it to the tools.

The call_model function sends messages to the LLM.

The router_function decides whether to end the conversation or call a tool.

Using StateGraph from LangGraph, I connect the nodes: agent, tools, start, and end.

Finally, in the Streamlit app, I created a simple interface with an input box, a button, and a display area for responses.â€

6. Conclusion & Future Scope (30â€“45 sec)

ğŸ“Œ End with vision:

â€œIn conclusion, this chatbot shows how LangGraph can orchestrate tools and language models together. With Groqâ€™s LLM for fast inference, Tavily for real-time search, and Streamlit for an interactive UI, this project demonstrates a modular and scalable chatbot framework.

In the future, I could extend it by adding memory for longer conversations, integrating multiple tools like weather or translation, and deploying it as a web app for public use.â€

â€œThank you for watching this demo!â€